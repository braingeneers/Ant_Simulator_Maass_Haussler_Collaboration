{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24dc087b",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<font color=\"magenta\" size=7><i>Ant Simulator</i></font>\n",
    "    \n",
    "\n",
    "    \n",
    "This implementation of a probabilistic skeleton enables innate motor control capabilities .  [Main Publication.](https://www.biorxiv.org/content/10.1101/2021.05.18.444689v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34deef21",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<div style=\"text-align:right\"><font size=7 color=\"orchid\" face='Brush Script MT'> to Start, Click - <button class=\"btn btn-sm btn-success\"><i class=\"fa fa-lg fa-id-card-o\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f48189",
   "metadata": {},
   "source": [
    "<h3 class=\"text-center\">Abstract</h3>\n",
    "\n",
    "Genetically encoded structure endows neural networks of the brain with innate computational ca\n",
    "pabilities that enable odor classification and basic motor control right after birth.\n",
    "It is also conjectured that the stereotypical laminar organization of neocortical microcircuits\n",
    "provides basic computing capabilities on which subsequent learning can build.\n",
    "However, it has remained unknown how nature achieves this.\n",
    "Insight from artificial neural networks does not help to solve this problem,\n",
    "since virtually all their computational capabilities result from learning.\n",
    "We show that genetically encoded control over connection probabilities between different types of neurons suffices for programming substantial computing capabilities into neural networks, providing a plausible mechanism for the evolution of innate capabilities.. This insight also provides a method for enhancing computing and\n",
    "learning capabilities of artificial neural networks and neuromorphic hardware through\n",
    "clever initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb488ed",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "**Description** \n",
    "\n",
    "Probabilistic skeletons (PS) are a mathematical model for encoding innate network structure in \n",
    "spiking neural networks.\n",
    "In this demo we show that a PS can be used to generate spiking networks that can solve a \n",
    "quadruped locomotion control task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b367927",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "**Running the code**\n",
    "\n",
    "Make sure that the `requirements.txt` are installed.\n",
    "The model can be run using the command: `python ant_task.py`\n",
    "The results can be found in: `ant/eval_runs/`. See the <font color=\"blue\">Code</font> section below for a more thorough description of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c8fb9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf4c3f",
   "metadata": {},
   "source": [
    "**Videos**\n",
    "\n",
    "The videos present results from two different spiking networks generated from the same probabalistic skeleton. We have optimized a probabilistic skeleton on performing a quadrupedal locomotion task. It can be used to sample an arbitrary amount of different spiking neural networks, which can all control the model of the ant. The two sample videos illustrate the performance of two different spiking networks sampled from the same PS. \n",
    "The spiking neural networks receive the angles of the ant as well as the height of the torso as input and output torques to the joints to generate a forward movement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf04b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e68343",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "Video(\"Data/videos/video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456a99a",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "Video(\"Data/videos/video2.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296ed39",
   "metadata": {},
   "source": [
    "# <font color=\"green\"> Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f40fe",
   "metadata": {},
   "source": [
    "These figures describe the model arhitecture and visualize the inner working of the spiking network. Use the **slider** below to view different figures. Figures and the videos can be found inside of the `visuals` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from IPython.core.display import display, Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faa214",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "figures=!cd Data/figures && ls\n",
    "@interact(  figure=(0,len(figures)-1) ) \n",
    "def displayer( figure ):\n",
    "    display(HTML(\"<h3 class='text-center'>\"+figures[figure]+\"</h3>;&nbsp;&nbsp;\"))\n",
    "    display(Image(filename=\"Data/figures/\"+figures[figure]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac5651",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "`description.png`: System  architecture, indicating network inputs and outputs, \n",
    "as well as the 8 joints  that are controlled by the network outputs\n",
    "\n",
    "`probabilistic_skeleton.png`: Probabilistic skeleton for solving this motor control task. \n",
    "Spiking neurons are grouped according to their genetic type. There are both excitatory neurons and inhibitory neurons with different parameters in the neuron model, which both have been fitted to measurement data of biological neurons. \n",
    "This PS uses 15 recurrent neuron types, 12 of which are excitatory and 3 are inhibitory. The connectivity of the model is \n",
    "defined through the connection probabilities between the types and the spatial distance between pairs of neurons.\n",
    "\n",
    "`spike_raster_1-3.png`: Spike raster of an RSNN sample with 458 neurons drawn from this probabilistic skeleton. \n",
    "The required spatial organization of network outputs emerges through population coding of 9 input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f9387",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "`input_output.png`: Sample dynamics of input and output variables of the RSNN controller on a larger timescale\n",
    "\n",
    "`vid_pca_z_plot.png`: The first row of the figure shows the movement of the ant over time. \n",
    "The second row depicts the PCA analysis of the spiking activity of the model. The most recent part of the \n",
    "trajectory has been plotted in red. \n",
    "Note, that a circular activity pattern emerged, which corresponds to the regular movement pattern of the ant. \n",
    "The third row illustrates the spike raster the PCA was based on.\n",
    "\n",
    "`chord_diagram.png`: The chord diagram depicts the connectivity between the neuron types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c31c91",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad13670",
   "metadata": {},
   "source": [
    "Here we highlight particularly important code in implementing our algorithm.\n",
    "To understand our implementation we reccomend looking at the code inside of the [ant_task.py](Code/ant_task.py) and [mdels.py](Code/models.py) files. \n",
    "[ant_task.py](Code/ant_task.py) contains the `main()` function which is the entrypoint to all code running inside the application. The code for constructing the spiking network and running it is defined inside the [models.py](Code/models.py) file. The two most important functions to read first are the `call` and the `sample_params` function shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad4bb3",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Call Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbbf8d",
   "metadata": {},
   "source": [
    "This function simulates the model of the spiking network. The is located inside of the [models.py](http://wetai.gi.ucsc.edu:8007/edit/Projects/Ant_Sim_Haussler_Maass_Collaboration/Code/models.py) file at line `593`. Consecutive calls to this function will computes the activity of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be66f89",
   "metadata": {},
   "source": [
    "``` python\n",
    "   def call(self, inputs, state, constants=None):\n",
    "        batch_size = inputs.shape[0]\n",
    "        if batch_size is None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "        external_current = inputs\n",
    "\n",
    "        z, v, r, psc_rise, psc = state\n",
    "\n",
    "        psc_rise = tf.reshape(psc_rise, (batch_size, self.n_glif_neurons, self._n_receptors))\n",
    "        psc = tf.reshape(psc, (batch_size, self.n_glif_neurons, self._n_receptors))\n",
    "\n",
    "        z_buf = tf.reshape(z, (self.all_flat_size, self.max_delay, -1))  # self.make_flat_shape(z)\n",
    "        z = z_buf[:, 0]  # z contains the spike from the prev time step\n",
    "        z_rec = z_buf[:, 1:]\n",
    "        inputs = self._compute_internal_currents(z_rec, external_current, batch_size)\n",
    "\n",
    "        new_psc_rise = self.syn_decay * psc_rise + inputs * self.psc_initial\n",
    "        new_psc = psc * self.syn_decay + self._dt * self.syn_decay * new_psc_rise\n",
    "\n",
    "        new_r = tf.nn.relu(r + z * self.t_ref - self._dt)\n",
    "\n",
    "        input_current = tf.reduce_sum(psc, -1)\n",
    "\n",
    "        if constants != None:\n",
    "            input_current = constants[0]\n",
    "\n",
    "        decayed_v = self.decay * v\n",
    "\n",
    "        gathered_g = self.param_g * self.e_l\n",
    "\n",
    "        c1 = input_current + gathered_g\n",
    "        new_v = decayed_v + self.current_factor * c1\n",
    "\n",
    "        new_z = spike_function(new_v, self.v_th)\n",
    "        if self.flags.less_excitable > 0.0:\n",
    "            excitation_mask = 1 - (1 - self.deletion_mask) * np.random.binomial(1,\n",
    "                                                                                1 - self.flags.less_excitable,\n",
    "                                                                                np.shape(self.deletion_mask))\n",
    "        else:\n",
    "            excitation_mask = self.deletion_mask\n",
    "        new_z = excitation_mask * new_z  # apply neuron deletion\n",
    "\n",
    "        old_new_v = tf.where(z > 0.5, self.v_reset, v)  # v_rec + reset_current_rec\n",
    "        new_v = tf.where(new_r > 0., old_new_v, new_v)\n",
    "        new_z = tf.where(new_r > 0., tf.zeros_like(new_z), new_z)\n",
    "\n",
    "        new_psc = tf.reshape(new_psc, (batch_size, self.n_glif_neurons * self._n_receptors))\n",
    "        new_psc_rise = tf.reshape(new_psc_rise, (batch_size, self.n_glif_neurons * self._n_receptors))\n",
    "\n",
    "        # the last neurons are the output neurons\n",
    "        new_z_out = new_z[..., -self.n_out_neurons:]\n",
    "        outputs = (new_z_out, dict(v_rec=new_v[..., :-self.n_out_neurons],\n",
    "                                   v_out=new_v[..., -self.n_out_neurons:],\n",
    "                                   z_rec=new_z[..., :-self.n_out_neurons],\n",
    "                                   z_out=new_z_out))\n",
    "\n",
    "        # add new time step to beginning buffer and drop last\n",
    "        new_z_buf = tf.concat((new_z[:, None], z_buf[:, :-1]), 1)\n",
    "        new_z_buf = tf.reshape(new_z_buf, (self.all_flat_size, -1))\n",
    "        new_state = (new_z_buf, new_v, new_r, new_psc_rise, new_psc)\n",
    "\n",
    "        return outputs, new_state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361351c0",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Sample Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed2f48",
   "metadata": {},
   "source": [
    "The function creates the parameters for the spiking network .  The code is located inside of the [models.py](http://wetai.gi.ucsc.edu:8007/edit/Projects/Ant_Sim_Haussler_Maass_Collaboration/Code/models.py) file at line `293`. One can  sample a spiking network  parameters form from the same probabilistic skeleton. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581f0fd",
   "metadata": {},
   "source": [
    "``` python\n",
    "    def sample_params(self):\n",
    "        # update params\n",
    "        self.update_params()\n",
    "        # update spatial structure\n",
    "        self.update_spatial_structure()\n",
    "        connection_probabilities, distance_factor = self.compute_connection_probabilities()\n",
    "\n",
    "        # apply connection constraints mask (no in->out, out->rec and out->out)\n",
    "        self.connection_parameter *= self.type_mask\n",
    "        connection_probabilities *= self.type_mask\n",
    "        if self.flags.spatial_input_to_single_type:\n",
    "            connection_probabilities *= self.input_restriction_type_mask\n",
    "\n",
    "        # compute in_weights indices\n",
    "        # select right section of dist matrix\n",
    "        in_dist_fact = distance_factor[:, :self.n_in_neurons, self.n_in_neurons:]\n",
    "        in_weights = self.create_weight_matrix(connection_probabilities, in_dist_fact,\n",
    "                                               self.in_neuron_type_ids, self.n_in_neurons,\n",
    "                                               self.glif_neuron_type_ids, self.n_glif_neurons,\n",
    "                                               n_receptors=self._n_receptors, quantize=True,\n",
    "                                               position=\"in\") * self.flags.w_in_coeff\n",
    "        self.in_weights.assign(in_weights)\n",
    "\n",
    "        # compute rec weights indices\n",
    "        rec_dist_fact = distance_factor[:, self.n_in_neurons:, self.n_in_neurons:]\n",
    "        rec_weights = self.create_weight_matrix(connection_probabilities, rec_dist_fact,\n",
    "                                                self.glif_neuron_type_ids, self.n_glif_neurons,\n",
    "                                                self.glif_neuron_type_ids, self.n_glif_neurons,\n",
    "                                                n_receptors=self._n_receptors, use_e_i=True,\n",
    "                                                quantize=True)\n",
    "        rec_weights *= self.w_out_coeff_mask\n",
    "        rec_weights = self.expand_ei_weights(rec_weights)\n",
    "        self.rec_weights.assign(rec_weights)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ee48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
